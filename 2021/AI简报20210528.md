[TOC]

> 导读： 本期为 AI 简报 20210528 期，请慢慢食用~
>
> ps: 强烈推荐阅读李沐大大得工作五年反思经验~
>
> 本文一共 37000 字，通篇阅读结束需要 10~15 分钟

# 嵌入式 AI

## 1.《2021人脸识别行业白皮书》发布

近日，智慧芽联合罗思咨询，共同发布《2021人脸识别行业白皮书》。

这本白皮书由多位专家共同撰写，从人脸识别行业现状、企业聚焦和技术发展情况，人脸识别在各个行业中的应用，人脸识别的风险预警机制及其研究成果等维度对人脸识别行业进行了深度剖析。

《2021人脸识别行业白皮书》总计71页，将从以下几方面为大家呈现人工智能行业的发展状况：

1、行业概况初探；

2、重点企业聚焦；

3、技术发展洞察；

4、应用热点追踪；

5、风险识别预警；

6、研究成果总结。

## 2. [ARM发布 Armv9 64位超级大小核心 | EETOP](https://mp.weixin.qq.com/s/XxQmM_SdiRVEAjYXCsGw6g)

> Armv9就是创造下一波3千亿个Arm芯片的前哨，也将加速AI应用、物联网（IoT）与5G的发展。

5 月 25 日消息 又到了每年一度的 Arm 架构更新的时候。在上个月 Arm 发布了最新的基础架构 Neoverse V1 和 Neoverse N2 CPU IP 之后，现在官方终于推出了移动端新架构。

今年，Arm 推出的东西比往年更多，包括面向移动和客户端的三种新一代微架构：旗舰级的 Cortex-X2，A78 继任者 Cortex-A710、A55 后继者 Cortex-A510。

这三款新的 SoC CPU 架构均基于 Armv9 兼容设计，旨在引领更强的架构 / ISA 变革，这在业界是很少见的。

除了新的 CPU 核心，我们还看到 DSU-110 采用了新的 L3 和集群设计，Arm 也在 interconnect IP 上进行了大量升级改进，包括采用了高速缓存一致性 CI-700 网状网络和 NI-700 片上网络 IP。

## 3. ST为STM32H7新整的人脸识别库，每秒3.6帧

![image-20210528154029518](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528154030.png)

> 原文：
>
> https://blog.st.com/fp-ai-facerec1/
>
> 官方文档：
>
> https://wiki.stmicroelectronics.cn/stm32mcu/wiki/FP-AI-FACEREC1_getting_started
>
> 下载地址：
>
> https://www.stmicroelectronics.com.cn/en/embedded-software/fp-ai-facerec.html

FP-AI-FACEREC是STM32Cube功能包，具有在STM32产品上运行的面部识别应用示例。

FP-AI-FACEREC可在基于STM32H7 MCU或STM32MP1 MPU的产品上基于面部识别功能开发高级功能。

FP-AI-FACEREC是一种完全嵌入式的AI解决方案，可以在微控制器或微处理器上本地处理图像，在注册阶段或识别阶段，不需要将任何个人数据发送到Cloud。

使用意法半导体的人脸识别库，可以根据最终用户自定义设备的行为，而最终用户可以使用低分辨率摄像头设备对其进行实时识别。

## 4. 1.4 TOPS算力，视觉AI SOM市场迎来“自适应”创新者

![img](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528155342.jpeg)

> 原文：
>
> https://www.eet-china.com/news/11463.html

赛灵思公司日前宣布推出Kria自适应系统模块(SOM)产品组合，这

款可量产化的小尺寸嵌入式板卡具备完整的软件堆栈与预构建的加速应用，可在基于边缘的应用中实现快速部署。

赛灵思工业、视觉、医疗及科学(ISM)市场总监Chetan Khona在接受媒体采访时表示，与芯片缩减设计(chip-down design)相比，Kria SOM允许开发者从设计周期中更为成熟的节点入手，进而将部署时间缩短多达9个月。

Kria SOM产品组合中的首款产品Kria K26，是专门针对智慧城市和智能工厂中的视觉AI应用打造的。当然，在赛灵思规划的路线图上，我们还看到了面向尺寸和成本受限型应用的成本优化型SOM，以及能够为开发者提供每瓦更高实时计算能力的高性能模块。

# AI 前沿

## 5. 通过知识蒸馏增强轻量级深度估计

![image-20210528155851827](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528155852.png)

> 论文地址：
>
> https://arxiv.org/abs/2105.06143

本文提出一种实时深度估计的轻量级网络，在速度、准确率、计算效率等均衡上表现优秀！性能优于FastDepth等网络，作者单位：AIRS, 港中文, 东北大学(日本) 

深度估计的先进性能是通过使用大型和复杂的神经网络来实现的。

尽管性能仍在不断提高，但我们认为深度估计必须准确高效。这是实际应用的初步要求。但是，由于模型的容量和准确性之间需要进行权衡，因此快速深度估计会降低性能。

在本文中，我们尝试使用轻量级网络进行高度准确的深度估计。为此，我们首先介绍一个可以实时估计深度图的紧凑型网络。

然后，我们将在技术上展示两种互补且必要的策略，以改善轻量级网络的性能。由于现实世界中场景的数量是无限的，所以首先是使用辅助数据，这会增加训练数据的多样性。第二个是使用知识蒸馏来进一步提高性能。通过广泛而严格的实验，我们证明了我们的方法在推理准确性，计算效率和泛化方面都优于以前的轻量级方法。与仅使用1％参数的最新方法相比，我们可以实现可比的性能，另一方面，我们的方法在很大程度上优于其他轻量方法。

## 6. [IJCAI 2021｜美团提出车道线检测新框架SGNet，精准且快速](https://mp.weixin.qq.com/s/1dwRw9u3mI9SGP-vqGHplQ)

![Image](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528155952.webp)

> 论文地址：
>
> https://arxiv.org/pdf/2105.05403.pdf

本文是来自美团视觉智能中心在车道线检测领域的最新研究成果，目前已被 IJCAI 2021 接收。

美团视觉技术团队对当前车道线检测存在的难点进行了重新思考，归纳为三个难点

- 缺乏对车道线统一且有效的表示方式
- 缺少对道路场景与车道线间结构关系的有效利用
- 难以扩展至车道线的其他属性。

基于此，研究者提出了一种结构信息引导的车道线检测框架 SGNet，该方法在公开车道线检测数据集上性能明显优于现有方法，同时预测速度可以达到 117FPS。

## 7. [阿里提出：最强无监督行人重识别方法 Cluster Contrast ReID](https://mp.weixin.qq.com/s/nyGBqg8Qgz1I02MSJlCTlg)

![Image](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528160135.png)

> 论文链接：
>
> https://arxiv.org/abs/2103.11568
>
> 代码连接：
>
> https://github.com/alibaba/cluster-contrast-reid

在行人重识别领域，如何获取海量标注数据，提高实际场景的重识别能力是工业界非常关注的一个问题。

无监督行人重识别已经有很多人在研究了，目前最好的方法是SPCL(葛艺潇：NeurIPS 2020 | 自步对比学习: 充分挖掘无监督学习样本), 在使用了Generalized Mean Pooling (GEM)之后，在Market1501数据集上达到了rank-1 89.5% 的效果，效果很好.

但是和有监督的方法，如Resnet50 + Circle loss (layumi/Person_reID_baseline_pytorch) rank-1 92.13% 或者 OSNet (Model Zoo - torchreid 1.4.0 documentation ) 94.2% rank-1相比仍然有一些差距。

SPCL提供了一个很强的unsupervised reid pipeline，可以启发我们去进行更深一步的探索。

基于此，我们提出了无监督Cluster Contrast ReID，在Market1501上跑到了rank-1 94.6%，已经超越了很多有监督的算法。在其他行人重识别数据集如Duke和MSMT17数据集上，也比最先进无监督re-ID方法mAP提高了7.5％，6.6％。

# 开源项目

## 8. [项目实践 | 从零开始边缘部署轻量化人脸检测模型——训练篇](https://mp.weixin.qq.com/s/t9cKGb4xCIxUlnGUrOtToQ) | 集智书童

![image-20210528161710672](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528161715.png)

该模型是针对边缘计算设备设计的轻量人脸检测模型。

- 在模型大小上，默认FP32精度下（.pth）文件大小为 1.04~1.1MB，推理框架int8量化后大小为 300KB 左右。
- 在模型计算量上，320x240的输入分辨率下 90~109 MFlops左右。
- 模型有两个版本，version-slim(主干精简速度略快)，version-RFB(加入了修改后的RFB模块，精度更高)。
- 提供320x240、640x480不同输入分辨率下使用widerface训练的预训练模型，更好的工作于不同的应用场景。

## 9. [目标检测实战：4种YOLO目标检测的C++和Python两种版本实现 | 极市平台](https://mp.weixin.qq.com/s/0Rt-1w2h0toFV5HKii7JZA)

![Image](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528162133.webp)

> Github1:
>
> https://github.com/hpc203/yolov34-cpp-opencv-dnn
>
> Github2:
>
> https://github.com/hpc203/yolov5-dnn-cpp-python
>
> Github3:
>
> https://github.com/hpc203/yolov5-dnn-cpp-python-v2

2020年，新出了几个新版本的YOLO目标检测，在微信朋友圈里转发的最多的有YOLOv4，Yolo-Fastest，YOLObile以及百度提出的PP-YOLO。在此之前，我已经在github发布过YOLOv4，Yolo-Fastest，YOLObile这三种YOLO基于OpenCV做目标检测的程序，但是这些程序是用Python编写的。接下来，我就使用C++编写一套基于OpenCV的YOLO目标检测，这个程序里包含了经典的YOLOv3，YOLOv4，Yolo-Fastest和YOLObile这4种YOLO目标检测的实现。

最终得结果是Yolo-Fastest运行速度最快，YOLObile号称是实时的，但是从结果看并不如此。并且查看它们的模型文件，可以看到Yolo-Fastest的是最小的。如果在ubuntu-gpu环境里运行，它还会更快。

整个程序的运行不依赖任何深度学习框架，只需要依赖OpenCV4这个库就可以运行整个程序，做到了YOLO目标检测的极简主义，这个在硬件平台部署时是很有意义的。建议在ubuntu系统里运行这套程序，上面展示的是在win10-cpu机器上的运行结果，而在ubuntu系统里运行，一张图片的前向推理耗时只有win10-cpu机器上的十分之一。

## 10. [Mac用户的福音：OCR新神器，一键转换屏幕上的任意文本 | 机器之心](https://mp.weixin.qq.com/s/lSEIrH7esxSX4NSwRF2DBg)

![image-20210528162420295](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210528162423.png)

> 项目地址：
>
> https://github.com/schappim/macOCR

Mac 平台上的 OCR 文字识别方法有很多，比如 iText、OCRKit 等。本文介绍的 macOCR 命令行应用程序使 Mac 用户有了一个新选择。

近日，GitHub 上又出现了一个非常火的 OCR 工具 macOCR，短短一天时间，就收获了近800赞。macOCR 是一个开源命令行应用程序，用户可以使用它将屏幕上的任何文本转换为剪贴板上的文本。

当你调用 ocr 命令时，一个类似于光标的「屏幕捕获」（screen capture）就会出现。如此一来，边框内的任何文本都将转换为纯文本。

项目作者提供了如下动图展示，将图片文本转换为了文本。

![Image](https://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWibtOlJkZ2FeNc7VFcfnKFzDBMMu94SrcwILRYiaYicW4ph3jgsBKzJiarxiavBv2wad1vLtUK1YHRyksQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

# 其他

**项目**

- [实操教程｜NCNN+Int8+YOLOv4量化模型和实时推理](https://mp.weixin.qq.com/s/yN_d4ytZlQ7NRmh2DN7_4Q)

- [实操教程｜使用图像分割来做缺陷检测的一个例子](https://mp.weixin.qq.com/s/ef6h0wefftIntq1xuvkFBA)
- [AI已经会刷LeetCode了 | 量子位](https://mp.weixin.qq.com/s/xv9Go_7UKtyHj_vlAKhO7w)

- [AI现在能教你画画了](https://mp.weixin.qq.com/s/xUK6k28cd7qz3n7T8M6iqg)

**福利**

- [TensorRT详细入门指北，如果你还不了解TensorRT，过来看看吧！](https://mp.weixin.qq.com/s/96w3wn2NnNXk5DB6NKkJsw)
- [Github标星1.2K，Visual Transformer 最全最新资源，包含期刊、顶会论文](https://mp.weixin.qq.com/s/vgdEgJOByZn5d2FoQ1jxcA)
- [收录超十年，Kaggle竞赛优胜解决方案、思路大合集！](https://mp.weixin.qq.com/s/oC6qI7LyDn3tjxKE60iEcA)
- [CV 面试问题详解宝典--目标检测篇](https://mp.weixin.qq.com/s/fwPYr__6WEOryjCTg0UFYA)

**强烈建议阅读**

- [李沐：工作五年反思](https://mp.weixin.qq.com/s/AL-n_azSvlz05sWjTFBomg)

**新闻**:

- [热点|真国风 AI 虚拟人！腾讯艾灵学会作诗书法新技能，以假乱真的那种](https://mp.weixin.qq.com/s/Jm_uYYylt1bWYpWOH7jm1Q)

- [全球首个落地的舞蹈动画合成系统，网易互娱AI Lab新技术入选SIGGRAPH 2021](https://mp.weixin.qq.com/s/pc8xumc7GHTGSWWnzQIotg)