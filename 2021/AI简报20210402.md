[TOC]

> 导读： 本期为 AI 简报 20210402 期，将为您带来 8 条相关新闻，明日寒食节~
>
> 记得有一期有小伙伴留言说需要手势识别相关,本期它来啦~
>
> 本文一共 2200 字，通篇阅读结束需要 5~7 分钟

# [1. 保姆级教程 | TensorFlow-YOLOv3 从本地训练到服务器部署全过程](https://mp.weixin.qq.com/s/M2iIJegBvgVuHME-u9V8fA) | 我爱计算机视觉

![Image](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402161645.png)

> 项目链接：
>
> https://github.com/Byronnar/tensorflow-serving-yolov3

本文为 52CV 粉丝投稿，分享对已开源的 tensorflow-yolov3 版本进行许多细节上算法改进，步骤详细，非常适合新手入门。

本项目主要对原 tensorflow-yolov3 版本做了许多细节上的改进,

增加了TensorFlow-Serving 工程化部署, 训练了多个数据集，包括 Visdrone2019, 安全帽等数据集, 

安全帽上 mAP 在 98% 左右, 推理速度1080上608 的尺寸大概25fps。

本项目配有完善的说明, 如想你也想入门 TensorFlow 服务端部署, 那么, 这个项目是你非常好的选择.

# [2. 更稳定的手势识别方法--基于手部骨架与关键点检测](https://mp.weixin.qq.com/s/y4oYLjxC7ixN4Zzwo0l04g) | OpenCV与AI深度学习

![Image](https://mmbiz.qpic.cn/mmbiz_gif/rDAib0gF5OjaCqwls5bhh2V8XT4Jcyic0QVCrTDM6pkyyk7O66ia5tB1icTqYrOI6bgFueFhVMvylBYlnkmhn2yDiaQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

> github地址：
>
> https://github.com/google/mediapipe

本期将介绍并演示基于MediaPipe的手势骨架与特征点提取步骤以及以此为基础实现手势识别的方法。

关于MediaPipe以前有相关文章介绍，可以参看下面链接：

[Google开源手势识别--基于TF Lite/MediaPipe](http://mp.weixin.qq.com/s?__biz=MzU5NDM1MjU5Mg==&mid=2247484065&idx=1&sn=b0945e0ea8c5139e164946c8f29938c7&chksm=fe03c21ec9744b08b03219ef910df10f181c95d091e513cb601fd6f080d9f554bab662e88389&scene=21#wechat_redirect)

它能做些什么？请看上面的动图.

实现步骤:

> 参考链接:
>
> https://google.github.io/mediapipe/solutions/hands 

- (1) 安装mediapipe，执行pip install mediapipe
- (2) 下载手势检测与骨架提取模型
- (3) 代码测试(摄像头实时测试)

**总结**：MediaPipe手势检测与骨架提取模型识别相较传统方法更稳定，而且提供手指关节的3D坐标点，对于手势识别与进一步手势动作相关开发有很大帮助。

# [3. 加拿大小哥用树莓派做了一个狗子探测器：实时识别路过的狗子，还能向狗主人“表白”](https://mp.weixin.qq.com/s/Vuu40VizZ2Adm3-qxyXS1A) | 大数据文摘

![](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402162210.png)

> Github:
>
> https://github.com/rydercalmdown/dog_detector

**“吸狗一时爽，一直吸狗一直爽”**

加拿大小哥Ryder亲手做了一个**狗子探测器**，

这个探测器还和扩音喇叭联结在了一起，但凡有人遛狗经过了他们家，

探测器首先会进行**识别**，然后这个喇叭就会**提醒**他，“快来吸狗啦！”

这还不止，Ryder还突发奇想，这些狗子都这么可爱，它们的主人也应该得到赞赏。

于是，他对整个系统进行了改进。现在这个扩音喇叭不仅能提醒他赶紧吸狗，还**能对着路边的狗主人大声说到，“我喜欢你家的狗子**（I like your dog）”。

**超简单的狗子探测器，只需树莓派，项目已开源**

其实整个项目的思路也很简单，只需要去识别经过的狗子，然后通知他就行了。

# [4. 轻量级NLP工具Trankit开源，中文处理更精准，超越斯坦福Stanza，内存占用小45%](https://mp.weixin.qq.com/s/BGe4J2ByWx84tUDgIANqzA) | 量子位

![](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402162420.png)

> Github仓库：
> https://github.com/nlp-uoregon/trankit
>
> 在线Demo：
> http://nlp.uoregon.edu/trankit
>
> 相关论文：
> https://arxiv.org/pdf/2101.03289.pdf

最新轻量级多语言NLP工具集Trankit发布1.0版本，来自俄勒冈大学。

基于Transformer，性能已超越之前的热门同类项目**斯坦福Stanza**。

Trankit支持多达56种语言，除了简体和繁体中文以外，还支持**文言文**。

先来看一组Trankit与Stanza对文言文进行**依存句法分析**的结果。

可以看到，Stanza错误的将“有朋自远方来”中的“有”和“来”两个动词判断成**并列关系**。

在简体中文的**词性标注**任务上，Trankit对“自从”一词处理也更好。

与Stanza一样，Trankit也是基于Pytorch用原生Python实现，对广大Python用户非常友好。

Trankit在GPU加持下**加速更多**，且**占用内存更小**，作为一个轻量级NLP工具集更适合普通人使用。

# [5. 妙啊！那个用文言文编程的小哥，竟从28万行唐诗中找出了对称矩阵](https://mp.weixin.qq.com/s/RMgVslAafkTZIPK7H40ppg) | 量子位

![](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402162617.png)

> Github:
>
> https://github.com/LingDong-/magic-square-poems

横着读是一首诗，竖着读还是这首诗！

这首诗可不是乱编的，其中的诗句都来自**《全唐诗》**，读起来也颇有意境。

创造这个奇妙组合的，不是文学研究大师，而是一位程序员小哥。

他用计算机，找出了所有符合规律的古诗，还在Github上开源了代码。

就连README文件，也颇具个性.

这首诗，初看只是横竖都能读，但如果把其中汉字编码成数字再看的话，会发现：

原来，这是个**对称矩阵**！

# [6. 屠榜各大CV任务! Swin Transformer对CNN的降维打击](https://mp.weixin.qq.com/s/t_J0MODtWzfnJse0aNGyWg) | Smarter

![Image](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402163122.png)

> paper:
>
> https://arxiv.org/abs/2103.14030
>
> code:
>
> https://github.com/microsoft/Swin-Transformer
>
> 一作解读: 
>
> https://www.zhihu.com/question/437495132/answer/1800881612

最近Transformer的文章眼花缭乱，但是精度和速度相较于CNN而言还是差点意思，直到Swin Transformer的出现，让人感觉到了一丝丝激动，Swin Transformer可能是CNN的完美替代方案。

作者分析表明，Transformer从NLP迁移到CV上没有大放异彩主要有两点原因：

1. 两个领域涉及的scale不同，NLP的scale是标准固定的，而CV的scale变化范围非常大。
2. CV比起NLP需要更大的分辨率，而且CV中使用Transformer的计算复杂度是图像尺度的平方，这会导致计算量过于庞大。

为了解决这两个问题，Swin Transformer相比之前的ViT做了两个改进：

1. 引入CNN中常用的层次化构建方式构建层次化Transformer

2. 引入locality思想，对无重合的window区域内进行self-attention计算。

相比于ViT，Swin Transfomer计算复杂度大幅度降低，具有输入图像大小线性计算复杂度。

# [7. 熬了几个通宵，我写了份CUDA新手入门代码](https://mp.weixin.qq.com/s/OB0B0IfgxxfsYOQoj3eQqQ) |  算法码上来

![](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402163347.png)

> Github:
>
> https://github.com/godweiyang/NN-CUDA-Example

在用PyTorch或者TensorFlow搭积木的时候，你是不是也遇到过下面这些情况：

- 自带的算子及其组合都无法满足你超（bian）常（tai）的计算需求。
- 自带的算子不可导，需要自己定义反向传播的梯度，例如argmax。
- 自带的算子太慢了，严重影响了你发paper的速度。

这时候你就会想，要是能自己实现一个速度又快、又能满足需求的算子就好了。

你想到了CUDA，自己写一个CUDA算子不就完事了嘛！

然后问题又来了，写是写完了，怎么用python代码调用它呢？

还有一个问题，这个算子它没梯度啊，自动求导机制不顶用了！

你去网上各种搜索，方法倒是全有，但是源码都好复杂，你一个新手怎么可能有心思看完那么复杂的教程？

这时候，你突然看到了这篇文章，看完后你惊呼：“怎么会有这么简洁的示例代码，这就是我想要的！”

没错，这就是作者熬了好几个通宵，查了无数bug后，写出来的一份示例代码。

# [8. 有bug！PyTorch在AMD CPU的计算机上卡死了](https://mp.weixin.qq.com/s/4X_SP0unbRH9zAPfpsEfsA) | 机器之心

![](https://gitee.com/lebhoryi/PicGoPictureBed/raw/master/img/20210402163419.png)

> GitHub 地址：
>
> https://github.com/pytorch/pytorch/issues/52142

AMD，No？PyTorch在AMD CPU的机器上出现死锁了。

前段时间发布的 PyTorch 1.8 新增了对 AMD ROCm 的支持，对于想在 AMD 上用 PyTorch 进行深度学习的开发者来说，这是一个好消息。 

但是，对使用 AMD cpu 的开发者用 PyTorch 做 AI 开发，也许没那么顺利。

这不，我们就从 PyTorch 的 Github 上发现这么一个还未解决的 issue。

有开发者表示：PyTorch 在 AMD CPU 的计算机上，用数据并行单机和多 GPU 训练 CNN 会导致死锁，而相同的代码在 Intel CPU 的计算机中就不会出现死锁。TensorFlow 也不会出现这种问题。

# 其他

- [哭了！2020图灵奖颁给编程的回忆——Jeff Dean 的编译启蒙书](https://mp.weixin.qq.com/s/dUgK9onroA_Uhb5ZKHSPYQ)
- [10年重大更新！对决英特尔，ARM v9架构正式发布，华为海思还有使用权吗？](https://mp.weixin.qq.com/s/sKpklPRaYQ9F2pWatvbVKQ)
- [斯坦福科学家开源了莫德纳mRNA新冠疫苗的基因测序，在GitHub上](https://mp.weixin.qq.com/s/6IscAZSpZzoxdwothL98Lw)
- [无内鬼，来点ICML/ACL审稿人笑话](https://mp.weixin.qq.com/s/GuAn6r9-xVl5LyS8A7LJRg)